{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc16d48-ed86-400b-84a6-f8080cd37ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Continuous Bag of Words (CBOW) Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7524e0-6ea9-4d00-8288-8963d6225c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "a. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfe263b8-cd2a-491b-9e3e-25feabad4f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"the quick brown fox jumps over the lazy dog\",\n",
    "    \"the dog barks at the fox\",\n",
    "    \"the fox is quick and the dog is lazy\",\n",
    "    \"dogs and foxes are different\"\n",
    "]\n",
    "\n",
    "# Tokenize corpus to integer sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "vocab_size = len(word2idx) + 1  # +1 for padding (index 0)\n",
    "print(f\"Vocabulary Size: {vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02e44d-99c0-445d-9577-923d4d1c52ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "b. Generate Training Data for CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6b6c27-5e1a-4269-b4e1-5bded04e95fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 13\n",
      "Sample context (word indices): [1 4 2 9], target (one-hot): [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "data = []\n",
    "\n",
    "for sequence in sequences:\n",
    "    for idx in range(window_size, len(sequence) - window_size):\n",
    "        context = sequence[idx - window_size: idx] + sequence[idx + 1: idx + window_size + 1]\n",
    "        target = sequence[idx]\n",
    "        data.append((context, target))\n",
    "\n",
    "print(f\"Number of training samples: {len(data)}\")\n",
    "\n",
    "# Prepare inputs and outputs\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for context, target in data:\n",
    "    X.append(context)\n",
    "    y.append(target)\n",
    "\n",
    "X = np.array(X)\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "print(f\"Sample context (word indices): {X[0]}, target (one-hot): {y[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec67482-0a9c-4684-9330-8b280facd7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c. Define and Train the CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28fa675a-e553-4ae6-ac2f-3529916de7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m10\u001b[0m)               │             \u001b[38;5;34m170\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)                  │             \u001b[38;5;34m187\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">357</span> (1.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m357\u001b[0m (1.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">357</span> (1.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m357\u001b[0m (1.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 1s - 552ms/step - accuracy: 0.0769 - loss: 2.8340\n",
      "Epoch 2/100\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.0769 - loss: 2.8323\n",
      "Epoch 3/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.0769 - loss: 2.8306\n",
      "Epoch 4/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.0769 - loss: 2.8289\n",
      "Epoch 5/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.0769 - loss: 2.8272\n",
      "Epoch 6/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.0769 - loss: 2.8255\n",
      "Epoch 7/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.0769 - loss: 2.8238\n",
      "Epoch 8/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.0769 - loss: 2.8221\n",
      "Epoch 9/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.0769 - loss: 2.8204\n",
      "Epoch 10/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.0769 - loss: 2.8187\n",
      "Epoch 11/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.0769 - loss: 2.8171\n",
      "Epoch 12/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.0769 - loss: 2.8154\n",
      "Epoch 13/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.0769 - loss: 2.8137\n",
      "Epoch 14/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 0.1538 - loss: 2.8120\n",
      "Epoch 15/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.1538 - loss: 2.8103\n",
      "Epoch 16/100\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.1538 - loss: 2.8086\n",
      "Epoch 17/100\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.1538 - loss: 2.8069\n",
      "Epoch 18/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.2308 - loss: 2.8052\n",
      "Epoch 19/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.2308 - loss: 2.8035\n",
      "Epoch 20/100\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.2308 - loss: 2.8018\n",
      "Epoch 21/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.2308 - loss: 2.8001\n",
      "Epoch 22/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.2308 - loss: 2.7984\n",
      "Epoch 23/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 0.3077 - loss: 2.7967\n",
      "Epoch 24/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3846 - loss: 2.7949\n",
      "Epoch 25/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 0.3846 - loss: 2.7932\n",
      "Epoch 26/100\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.3846 - loss: 2.7914\n",
      "Epoch 27/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3846 - loss: 2.7897\n",
      "Epoch 28/100\n",
      "1/1 - 0s - 29ms/step - accuracy: 0.3846 - loss: 2.7879\n",
      "Epoch 29/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.3846 - loss: 2.7862\n",
      "Epoch 30/100\n",
      "1/1 - 0s - 77ms/step - accuracy: 0.3846 - loss: 2.7844\n",
      "Epoch 31/100\n",
      "1/1 - 0s - 43ms/step - accuracy: 0.3846 - loss: 2.7826\n",
      "Epoch 32/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.3846 - loss: 2.7808\n",
      "Epoch 33/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 0.3846 - loss: 2.7790\n",
      "Epoch 34/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3846 - loss: 2.7772\n",
      "Epoch 35/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3846 - loss: 2.7754\n",
      "Epoch 36/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.3846 - loss: 2.7735\n",
      "Epoch 37/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3846 - loss: 2.7717\n",
      "Epoch 38/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.3846 - loss: 2.7698\n",
      "Epoch 39/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.3846 - loss: 2.7680\n",
      "Epoch 40/100\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.3846 - loss: 2.7661\n",
      "Epoch 41/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3846 - loss: 2.7642\n",
      "Epoch 42/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3846 - loss: 2.7623\n",
      "Epoch 43/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3846 - loss: 2.7604\n",
      "Epoch 44/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3846 - loss: 2.7585\n",
      "Epoch 45/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3846 - loss: 2.7565\n",
      "Epoch 46/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3846 - loss: 2.7546\n",
      "Epoch 47/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3846 - loss: 2.7526\n",
      "Epoch 48/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3846 - loss: 2.7506\n",
      "Epoch 49/100\n",
      "1/1 - 0s - 30ms/step - accuracy: 0.3846 - loss: 2.7486\n",
      "Epoch 50/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.3846 - loss: 2.7466\n",
      "Epoch 51/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3846 - loss: 2.7446\n",
      "Epoch 52/100\n",
      "1/1 - 0s - 39ms/step - accuracy: 0.3846 - loss: 2.7426\n",
      "Epoch 53/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3846 - loss: 2.7405\n",
      "Epoch 54/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.3846 - loss: 2.7385\n",
      "Epoch 55/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.3846 - loss: 2.7364\n",
      "Epoch 56/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3846 - loss: 2.7343\n",
      "Epoch 57/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3846 - loss: 2.7322\n",
      "Epoch 58/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3846 - loss: 2.7301\n",
      "Epoch 59/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3846 - loss: 2.7279\n",
      "Epoch 60/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 0.3846 - loss: 2.7258\n",
      "Epoch 61/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3846 - loss: 2.7236\n",
      "Epoch 62/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3077 - loss: 2.7214\n",
      "Epoch 63/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3077 - loss: 2.7193\n",
      "Epoch 64/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3077 - loss: 2.7170\n",
      "Epoch 65/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.3077 - loss: 2.7148\n",
      "Epoch 66/100\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.3077 - loss: 2.7126\n",
      "Epoch 67/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.3077 - loss: 2.7103\n",
      "Epoch 68/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.3077 - loss: 2.7081\n",
      "Epoch 69/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3077 - loss: 2.7058\n",
      "Epoch 70/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3077 - loss: 2.7035\n",
      "Epoch 71/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3077 - loss: 2.7012\n",
      "Epoch 72/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3077 - loss: 2.6988\n",
      "Epoch 73/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3077 - loss: 2.6965\n",
      "Epoch 74/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3077 - loss: 2.6941\n",
      "Epoch 75/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3077 - loss: 2.6917\n",
      "Epoch 76/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3077 - loss: 2.6893\n",
      "Epoch 77/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.3077 - loss: 2.6869\n",
      "Epoch 78/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.3077 - loss: 2.6845\n",
      "Epoch 79/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 0.3077 - loss: 2.6821\n",
      "Epoch 80/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3077 - loss: 2.6796\n",
      "Epoch 81/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 0.3077 - loss: 2.6771\n",
      "Epoch 82/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3077 - loss: 2.6746\n",
      "Epoch 83/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3077 - loss: 2.6721\n",
      "Epoch 84/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3077 - loss: 2.6696\n",
      "Epoch 85/100\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.3077 - loss: 2.6671\n",
      "Epoch 86/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.3077 - loss: 2.6645\n",
      "Epoch 87/100\n",
      "1/1 - 0s - 40ms/step - accuracy: 0.3077 - loss: 2.6619\n",
      "Epoch 88/100\n",
      "1/1 - 0s - 35ms/step - accuracy: 0.3077 - loss: 2.6593\n",
      "Epoch 89/100\n",
      "1/1 - 0s - 37ms/step - accuracy: 0.3077 - loss: 2.6567\n",
      "Epoch 90/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 0.3077 - loss: 2.6541\n",
      "Epoch 91/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 0.3077 - loss: 2.6515\n",
      "Epoch 92/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3077 - loss: 2.6488\n",
      "Epoch 93/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3077 - loss: 2.6461\n",
      "Epoch 94/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3077 - loss: 2.6435\n",
      "Epoch 95/100\n",
      "1/1 - 0s - 34ms/step - accuracy: 0.3077 - loss: 2.6408\n",
      "Epoch 96/100\n",
      "1/1 - 0s - 36ms/step - accuracy: 0.3077 - loss: 2.6380\n",
      "Epoch 97/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3077 - loss: 2.6353\n",
      "Epoch 98/100\n",
      "1/1 - 0s - 31ms/step - accuracy: 0.3077 - loss: 2.6325\n",
      "Epoch 99/100\n",
      "1/1 - 0s - 33ms/step - accuracy: 0.3077 - loss: 2.6298\n",
      "Epoch 100/100\n",
      "1/1 - 0s - 32ms/step - accuracy: 0.3077 - loss: 2.6270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19aee2a46e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Lambda, Dense\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "embedding_dim = 10\n",
    "\n",
    "# Input: context words (window_size*2)\n",
    "input_words = Input(shape=(window_size * 2,))\n",
    "\n",
    "# Embedding layer\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=window_size * 2)(input_words)\n",
    "\n",
    "# Average embeddings of context words\n",
    "avg_embedding = Lambda(lambda x: K.mean(x, axis=1))(embedding)\n",
    "\n",
    "# Output layer: softmax over vocab\n",
    "output = Dense(vocab_size, activation='softmax')(avg_embedding)\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=input_words, outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train\n",
    "model.fit(X, y, epochs=100, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b6a5e-a81a-4e96-b9ed-c6a1e055469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d. Output: Testing the Model's Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c75ecdd-f033-43d6-b0b9-b85a3c9fda91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Given context words ['the', 'quick', 'jumps', 'over'], predicted target word is 'and'\n"
     ]
    }
   ],
   "source": [
    "def predict_word(context_words):\n",
    "    context_seq = [word2idx.get(word, 0) for word in context_words]\n",
    "    context_seq = np.array(context_seq).reshape(1, -1)\n",
    "    pred = model.predict(context_seq)\n",
    "    predicted_index = np.argmax(pred)\n",
    "    return idx2word.get(predicted_index, \"Unknown\")\n",
    "\n",
    "# Example test\n",
    "test_context = ['the', 'quick', 'jumps', 'over']  # context words around a target\n",
    "predicted_word = predict_word(test_context)\n",
    "print(f\"Given context words {test_context}, predicted target word is '{predicted_word}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
